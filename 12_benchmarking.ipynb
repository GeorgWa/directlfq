{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_lines(protvals, log = True):\n",
    "    \"\"\"plot peptide profiles for a protein\"\"\"\n",
    "    colors = plt.cm.tab20c(np.linspace(0,1,protvals.shape[0]))\n",
    "    #cmap = plt.get_cmap(\"tab20c\")\n",
    "    idx = 0\n",
    "    for row in protvals:\n",
    "        if not log:\n",
    "            row = 2**row\n",
    "        plt.plot(row, c= colors[idx])\n",
    "        idx+=1\n",
    "    median_row = np.nanmedian(protvals, axis=0)\n",
    "    print(median_row)\n",
    "    plt.plot(median_row, c = 'black',linewidth =3 )\n",
    "    plt.show()\n",
    "\n",
    "def plot_points(protvals, log = True):\n",
    "    colors = plt.cm.tab20c(np.linspace(0,1,protvals.shape[0]))\n",
    "    #cmap = plt.get_cmap(\"tab20c\")\n",
    "    idx = 0\n",
    "    for row in protvals:\n",
    "        if not log:\n",
    "            row = 2**row\n",
    "        x_coord = list(range(len(row)))\n",
    "        plt.scatter(x_coord,row, c= colors[idx])\n",
    "        idx+=1\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "def get_tps_fps(result_df, prot2org_file, thresh = 0.05, fc_thresh = 0.3):\n",
    "    annotated = annotate_dataframe(result_df, prot2org_file)\n",
    "    condpairs = result_df[\"condpair\"].drop_duplicates()\n",
    "\n",
    "\n",
    "    for condpair in condpairs:\n",
    "        annotated_condpair = annotated[annotated[\"condpair\"]==condpair]\n",
    "        num_tps = sum(annotated_condpair[\"TP\"])\n",
    "        num_fps = sum(annotated_condpair[\"FP\"])\n",
    "        annotated_fcfilt = annotated_condpair[annotated[\"log2fc\"] >fc_thresh]\n",
    "        num_regulated_prots = sum(annotated_fcfilt[\"fdr\"]<thresh)\n",
    "        num_true_positives = sum(annotated_fcfilt[\"TP\"] &(annotated_fcfilt[\"fdr\"]<0.05))\n",
    "        num_false_positives = sum(annotated_fcfilt[\"FP\"] &(annotated_fcfilt[\"fdr\"]<0.05))\n",
    "        fpr = num_false_positives/num_regulated_prots\n",
    "\n",
    "        print(f'condpair {condpair}')\n",
    "        print(f\"total TPs {num_tps}\")\n",
    "        print(f\"total FPs {num_fps}\")\n",
    "        print(f'regulated {num_regulated_prots}')\n",
    "        print(f'false positives {num_false_positives}')\n",
    "        print(f'true positives {num_true_positives}')\n",
    "        print(f'regulated control {num_false_positives+num_true_positives}')\n",
    "        print(f'FPR {fpr}')\n",
    "\n",
    "        assert fpr < 0.06\n",
    "\n",
    "\n",
    "def annotate_dataframe(result_df, prot2org_file):\n",
    "    prot2org = pd.read_csv(prot2org_file, sep = \"\\t\")\n",
    "    prot2org[\"FP\"] = (prot2org[\"organism\"] == \"Homo sapiens\")\n",
    "    prot2org[\"TP\"] = (prot2org[\"organism\"] == \"Saccharomyces cerevisiae\")\n",
    "    prot2org = prot2org[(prot2org[\"FP\"] | prot2org[\"TP\"])]\n",
    "    print(f\"df size before {len(result_df.index)}\")\n",
    "    annotated = pd.merge(result_df, prot2org, how='inner', on = \"protein\")\n",
    "    print(f\"df size after {len(annotated.index)}\")\n",
    "    return annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "def compare_to_reference(result_df, reference_file, condpair):#put in condpair as tuple\n",
    "    result_df = result_df[result_df[\"condpair\"]==condpair]\n",
    "\n",
    "    ref_df = pd.read_csv(reference_file, sep = \"\\t\")\n",
    "    merged = pd.merge(result_df, ref_df, how='inner', on = \"protein\",suffixes = [\"\", \"_ref\"])\n",
    "    ax_p = merged.plot.scatter(x='pval_ref',y='pval')\n",
    "    plt.show()\n",
    "    ax_fc = merged.plot.scatter(x='log2FC_ref',y='fc')\n",
    "    plt.show()\n",
    "    ax_fdr = merged.plot.scatter(x='fdr_ref',y='fdr')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "def compare_normalization(ref_normalization_file, norm1_df, norm2_df):\n",
    "    ref_normed = pd.read_csv(ref_normalization_file, sep =\"\\t\").set_index('peptide')\n",
    "\n",
    "    merged = pd.merge(norm1_df, norm2_df, how='inner',  left_index = True, right_index = True)\n",
    "    columns = merged.columns\n",
    "    merged = pd.merge(ref_normed, merged, how='inner', left_index = True, right_index = True, suffixes = [\"_ref\", \"\"])\n",
    "\n",
    "    for i in range(len(columns)):\n",
    "        sample1 = columns[i]\n",
    "        sample2 = sample1+\"_ref\"\n",
    "        ax_p = merged.plot.scatter(x=sample1,y=sample2)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def print_nonref_hits(protein_ref, protein_df, peptide_ref, peptide_df, outdir):\n",
    "    prots_nonref_df =  protein_df[~(protein_df[\"protein\"].isin(protein_ref[\"protein\"].to_list()))]#the tilde inverts the boolean vector\n",
    "    peps_nonref_df = peptide_df[~(peptide_df[\"peptide\"].isin(peptide_ref[\"peptide\"].to_list()))]\n",
    "    prots_nonref_df.to_csv(f\"{outdir}/nonref_proteins.tsv\", sep = \"\\t\", index = False)\n",
    "    peps_nonref_df.to_csv(f\"{outdir}/nonref_peptides.tsv\", sep = \"\\t\", index = False)\n",
    "    #display(peps_nonref_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import functools\n",
    "\n",
    "\n",
    "class ResultsTable():\n",
    "    def __init__(self, input_file, input_name):\n",
    "        self._input_file = input_file\n",
    "        self._samples_c1 = None\n",
    "        self._samples_c2 = None\n",
    "        self.input_name = input_name\n",
    "        self.protein_column = \"protein\"\n",
    "        self.organism_column = \"organism\"\n",
    "        self.log2fc_column = 'log2fc'\n",
    "        self.mean_intensity_column = 'mean_intensity'\n",
    "        self.formated_dataframe = None\n",
    "\n",
    "    \n",
    "    def get_proteins(self):\n",
    "        return self.formated_dataframe[self.protein_column]\n",
    "\n",
    "    def _add_mean_intensity_column(self):\n",
    "        self._add_median_intensity_columns_for_each_condition()\n",
    "        self.formated_dataframe[self.mean_intensity_column] = self.formated_dataframe[['median_intensity_c1', 'median_intensity_c2']].mean(axis = 1)\n",
    "\n",
    "    \n",
    "    def _add_median_intensity_columns_for_each_condition(self):\n",
    "        self.formated_dataframe['median_intensity_c1'] = self.formated_dataframe[self._samples_c1].median(axis =1)\n",
    "        self.formated_dataframe['median_intensity_c2'] = self.formated_dataframe[self._samples_c2].median(axis =1)\n",
    "\n",
    "    def _add_log2fc_column(self):\n",
    "        self.formated_dataframe[self.log2fc_column] = [np.log2(x[0]) - np.log2(x[1]) for x in zip(self.formated_dataframe['median_intensity_c1'], self.formated_dataframe['median_intensity_c2'])]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResultsTableDirectLFQ(ResultsTable):\n",
    "    def __init__(self, input_file, input_name,  samples_c1, samples_c2):\n",
    "        super().__init__(input_file, input_name)\n",
    "        self._samples_c1 = samples_c1\n",
    "        self._samples_c2 = samples_c2\n",
    "        self._define_formatted_dataframe()\n",
    "        \n",
    "    def _define_formatted_dataframe(self):\n",
    "        self._load_directlfq_output()\n",
    "        self._add_median_intensity_columns_for_each_condition()\n",
    "        self._add_log2fc_column()\n",
    "        self._add_mean_intensity_column()\n",
    "        \n",
    "    def _load_directlfq_output(self):\n",
    "        self.formated_dataframe =  pd.read_csv(self._input_file, sep = \"\\t\")\n",
    "\n",
    "\n",
    "class ResultsTableIq(ResultsTable):\n",
    "    def __init__(self, input_file, input_name,  samples_c1, samples_c2):\n",
    "        super().__init__(input_file, input_name)\n",
    "        self._samples_c1 = samples_c1\n",
    "        self._samples_c2 = samples_c2\n",
    "        self._define_formatted_dataframe()\n",
    "        \n",
    "    def _define_formatted_dataframe(self):\n",
    "        self._load_directlfq_output()\n",
    "        self.formated_dataframe[self._samples_c1+self._samples_c2] = 2**self.formated_dataframe[self._samples_c1 + self._samples_c2]\n",
    "        self._add_median_intensity_columns_for_each_condition()\n",
    "        self._add_log2fc_column()\n",
    "        self._add_mean_intensity_column()\n",
    "        \n",
    "    def _load_directlfq_output(self):\n",
    "        self.formated_dataframe =  pd.read_csv(self._input_file, sep = \"\\t\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResultsTableMaxQuant(ResultsTable):\n",
    "    def __init__(self, input_file, input_name,  samples_c1, samples_c2):\n",
    "        super().__init__(input_file, input_name)\n",
    "        self._samples_c1 = samples_c1\n",
    "        self._samples_c2 = samples_c2\n",
    "        self._define_formatted_dataframe()\n",
    "\n",
    "    \n",
    "    def _define_formatted_dataframe(self):\n",
    "        self._load_maxquant_output()\n",
    "        self._add_median_intensity_columns_for_each_condition()\n",
    "        self._add_log2fc_column()\n",
    "        self._add_mean_intensity_column()\n",
    "\n",
    "    def _load_maxquant_output(self):\n",
    "        columns_to_use = self._samples_c1 + self._samples_c2 + [\"id\"]\n",
    "        self.formated_dataframe = pd.read_csv(self._input_file, sep = \"\\t\", usecols=columns_to_use)\n",
    "        self.formated_dataframe = self.formated_dataframe.rename({'id':self.protein_column},axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class OrganismAnnotator(ABC):\n",
    "    def __init__(self, mapping_file, protein_column = 'id', organism_column = 'Species'):\n",
    "        self._mapping_file = mapping_file\n",
    "        self._protein_column = protein_column\n",
    "        self._organism_column = organism_column\n",
    "        self._protein_organism_mapping_df = self._load_reduce_mapping_dataframe()\n",
    "        super().__init__()\n",
    "\n",
    "    def annotate_table_with_organism(self, results_table):\n",
    "\n",
    "        self.__add_organism_column_to_results_table(results_table)\n",
    "        self.__filter_non_matching_proteins(results_table)\n",
    "        \n",
    "\n",
    "    def save_protein_organism_map(self, outfile):\n",
    "        self._protein_organism_mapping_df.to_csv(outfile, sep = \"\\t\", index = None)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _load_reduce_mapping_dataframe(self):\n",
    "        pass\n",
    "    \n",
    "    def _filter_double_mapping_organism(self, protein2organism_df):\n",
    "        protein2organism_df = protein2organism_df[[\";\" not in x for x in protein2organism_df[self._organism_column].astype('str')]] #a semicolon seperates different organism entries\n",
    "        return protein2organism_df\n",
    "\n",
    "    def __add_organism_column_to_results_table(self, results_table):\n",
    "        protein2organism_dict = self.__get_protein2organism_dict()\n",
    "        proteins_resultstable = results_table.formated_dataframe[results_table.protein_column].astype('str')\n",
    "        results_table.formated_dataframe[results_table.organism_column] = [protein2organism_dict.get(x) for x in proteins_resultstable]\n",
    "\n",
    "    def __get_protein2organism_dict(self):\n",
    "        protein2organism = dict(zip(self._protein_organism_mapping_df[self._protein_column].astype('str'), self._protein_organism_mapping_df[self._organism_column]))\n",
    "        return protein2organism\n",
    "    \n",
    "    @staticmethod\n",
    "    def __filter_non_matching_proteins(results_table):\n",
    "        list_indicating_if_protein_matches = [x is not None for x in results_table.formated_dataframe[results_table.organism_column]]\n",
    "        results_table.formated_dataframe = results_table.formated_dataframe[list_indicating_if_protein_matches]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OrganismAnnotatorMaxQuant(OrganismAnnotator):\n",
    "    def __init__(self, mapping_file, protein_column = 'id', organism_column = 'Species'):\n",
    "        super().__init__(mapping_file=mapping_file, protein_column= protein_column, organism_column= organism_column)\n",
    "    \n",
    "    def _load_reduce_mapping_dataframe(self):\n",
    "        mapping_df = pd.read_csv(self._mapping_file, sep = \"\\t\", usecols=[self._protein_column, self._organism_column], encoding='latin1').drop_duplicates()\n",
    "        mapping_df = self._filter_double_mapping_organism(mapping_df)\n",
    "        return mapping_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OrganismAnnotatorSpectronaut(OrganismAnnotator):\n",
    "    def __init__(self, mapping_file,protein_column=\"PG.ProteinGroups\", organism_column=\"PG.Organisms\"):\n",
    "        super().__init__(mapping_file=mapping_file, protein_column= protein_column, organism_column= organism_column)\n",
    "    \n",
    "    def _load_reduce_mapping_dataframe(self):\n",
    "        mapping_df = pd.read_csv(self._mapping_file, sep = \"\\t\", usecols=[self._protein_column, self._organism_column], encoding='latin1').drop_duplicates()\n",
    "        mapping_df = self._filter_double_mapping_organism(mapping_df)\n",
    "        return mapping_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class OrganismAnnotatorDIANN(OrganismAnnotator):\n",
    "    def __init__(self, mapping_file, protein_column = 'Protein.Group', organism_column = 'Protein.Names'):\n",
    "        super().__init__(mapping_file=mapping_file, protein_column= protein_column, organism_column= organism_column)\n",
    "    \n",
    "    def _load_reduce_mapping_dataframe(self):\n",
    "        mapping_df = pd.read_csv(self._mapping_file, sep = \"\\t\", usecols=[self._protein_column, self._organism_column], encoding='latin1').drop_duplicates()\n",
    "        mapping_df[self._organism_column] = [self.__get_organism_from_protein_name(x) for x in mapping_df[self._organism_column]]\n",
    "        mapping_df = mapping_df.drop_duplicates()\n",
    "        return mapping_df\n",
    "    \n",
    "    @staticmethod\n",
    "    def __get_organism_from_protein_name(protein_name):\n",
    "        split_name = protein_name.split(\"_\")\n",
    "        if len(split_name) <2:\n",
    "            return \"None\"\n",
    "        else:\n",
    "            return split_name[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class PlotConfig():\n",
    "    def __init__(self, x_axisboundaries = None, y_axisboundaries = None, colormaps = None):\n",
    "        self.x_axisboundaries = x_axisboundaries\n",
    "        self.y_axisboundaries = y_axisboundaries\n",
    "        self._colormaps = colormaps\n",
    "\n",
    "class MultiOrganismIntensityFCPlotter():\n",
    "    def __init__(self, ax, resultstable_w_ratios, plotconfig = PlotConfig()):\n",
    "        self.ax = ax\n",
    "        self._resultstable_w_ratios = resultstable_w_ratios\n",
    "        self._organism_column = resultstable_w_ratios.organism_column\n",
    "        self._log2fc_column = resultstable_w_ratios.log2fc_column\n",
    "        self._mean_intensity_column = resultstable_w_ratios.mean_intensity_column\n",
    "        self._plotconfig = plotconfig\n",
    "        \n",
    "        self._all_organisms = self._get_all_organisms_used()\n",
    "        self._title = self._get_title()\n",
    "        self._scatter_per_organism()\n",
    "        \n",
    "\n",
    "    def _get_all_organisms_used(self):\n",
    "        return sorted(list(set(self._resultstable_w_ratios.formated_dataframe[self._organism_column].astype('str'))))\n",
    "    \n",
    "    def _get_title(self):\n",
    "        title = \"\"\n",
    "        for organism in self._all_organisms:\n",
    "            subtable_organism = self._get_organism_subtable(organism)\n",
    "            title += self._extend_title(organism,subtable_organism)\n",
    "        return title\n",
    "\n",
    "    def _scatter_per_organism(self):\n",
    "        complete_table = self._resultstable_w_ratios.formated_dataframe.copy()\n",
    "        complete_table[self._mean_intensity_column] = np.log2(complete_table[self._mean_intensity_column])\n",
    "        sns.scatterplot(data= complete_table, x = self._log2fc_column, y=self._mean_intensity_column, hue=self._organism_column, alpha=0.15, ax=self.ax, hue_order=self._all_organisms)\n",
    "        self.ax.set_title(self._title)\n",
    "        self.ax.set_xlim(self._plotconfig.x_axisboundaries)\n",
    "\n",
    "    def _get_organism_subtable(self, organism):\n",
    "        complete_table = self._resultstable_w_ratios.formated_dataframe\n",
    "        return complete_table[complete_table[self._organism_column] == organism]\n",
    "    \n",
    "    def _extend_title(self, organism, subtable_organism):\n",
    "        fcs = subtable_organism[self._log2fc_column].to_numpy()\n",
    "        fcs = fcs[np.isfinite(fcs)]\n",
    "        median_fc = np.nanmedian(fcs)\n",
    "        std_fc = np.nanstd(fcs)\n",
    "        num_ratios = sum(~np.isnan(fcs))\n",
    "        return f\"{organism} num:{num_ratios} median_FC:{median_fc:.2} STD:{std_fc:.2}\\n\"\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain CV distribution from ProteinIntensityTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import directlfq.utils as lfq_utils\n",
    "\n",
    "class ResultsTableBiological():\n",
    "    def __init__(self, results_file, samplemap, name):\n",
    "        self._results_file = results_file\n",
    "        self._samplemap = samplemap\n",
    "        self.name = name\n",
    "\n",
    "        self.results_df = None\n",
    "        self.cond2samples = {}\n",
    "\n",
    "        self._load_results_table()\n",
    "        self._load_cond2samples()\n",
    "\n",
    "    def _load_results_table(self):\n",
    "        self.results_df = pd.read_csv(self._results_file, sep = \"\\t\")\n",
    "        self.results_df = self.results_df.replace(0, np.nan)\n",
    "    \n",
    "    def _load_cond2samples(self):\n",
    "        samplemap_df = lfq_utils.load_samplemap(self._samplemap)\n",
    "        for sample, cond in zip(samplemap_df[\"sample\"], samplemap_df[\"condition\"]):\n",
    "            self.cond2samples[cond] = self.cond2samples.get(cond, []) + [sample]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "class CVInfoDataset():\n",
    "    def __init__(self, resultstable_biological):\n",
    "        self._results_table = resultstable_biological\n",
    "        self.name = resultstable_biological.name\n",
    "        self.cvs = []\n",
    "        self._calculate_cvs()\n",
    "\n",
    "    def _calculate_cvs(self):\n",
    "        for samples in self._results_table.cond2samples.values():\n",
    "            self._add_protein_cvs_for_condition(samples)\n",
    "    \n",
    "    def _add_protein_cvs_for_condition(self, samples):\n",
    "        subtable = self._results_table.results_df[samples]\n",
    "        protein_cvs = subtable.apply(self._cv_function,axis = 1)\n",
    "        protein_cvs = [x for x in protein_cvs if not np.isnan(x)]\n",
    "        self.cvs += list(protein_cvs)\n",
    "\n",
    "    @staticmethod\n",
    "    def _cv_function(x):\n",
    "        x = x.to_numpy()\n",
    "        if sum(~np.isnan(x)) <2:\n",
    "            return np.nan\n",
    "        return np.nanstd(x, ddof=1,) / np.nanmean(x) ##ddof ensures that the sample mean std estimate is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import seaborn as sns\n",
    "class CVDistributionPlotter():\n",
    "    def __init__(self, list_of_dataset_cv_infos, ax, cumulative=False, histtype='step', density=False, bins=150):\n",
    "        self._histconfig = HistPlotConfig(cumulative, histtype, density, bins)\n",
    "        self._list_of_dataset_cv_infos = list_of_dataset_cv_infos\n",
    "        self._ax  = ax\n",
    "        self._plot_histograms()\n",
    "\n",
    "    def _plot_histograms(self):\n",
    "        for dataset_cv_info in self._list_of_dataset_cv_infos:\n",
    "            self._add_cv_histogram(dataset_cv_info)\n",
    "        \n",
    "    def _add_cv_histogram(self, dataset_cv_info):\n",
    "        cvs = dataset_cv_info.cvs\n",
    "        all_cvs = len(cvs)\n",
    "        cvs = [x for x in cvs if x<0.75]\n",
    "        print(f\"{all_cvs - len(cvs)} are very large for {dataset_cv_info.name}\")\n",
    "        print(len(cvs))\n",
    "        print(np.nanmean(cvs))\n",
    "        print(np.nanmedian(cvs))\n",
    "        self._ax.hist(cvs, label=dataset_cv_info.name, cumulative=self._histconfig.cumulative, histtype=self._histconfig.histtype, density=self._histconfig.density, bins=self._histconfig.bins, linewidth = 1.5)\n",
    "        \n",
    "\n",
    "class HistPlotConfig():\n",
    "    def __init__(self,  cumulative, histtype, density, bins):\n",
    "        self.cumulative = cumulative\n",
    "        self.histtype = histtype\n",
    "        self.density = density\n",
    "        self.bins = bins\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test CV distribution estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "\n",
    "class ResTableTest(ResultsTableBiological):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "def test_cv_estimation():\n",
    "    restable_test = ResTableTest()\n",
    "    restable_test.name = \"name\"\n",
    "    restable_test.cond2samples = {\"cond\" : ['A', 'B'], \"othercond\" : ['A', 'C']}\n",
    "    restable_test.results_df = pd.DataFrame({'A' : [1, 2, 3], 'B' : [1, 2, 3], 'C' : [3, 2, 1]})\n",
    "    calced_cvs = CVInfoDataset(restable_test).cvs\n",
    "    assert np.allclose([0.0, 0.0, 0.0, 0.7071067811865476, 0.0, 0.7071067811865476], calced_cvs)\n",
    "\n",
    "test_cv_estimation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683 are very large for diann\n",
      "24479\n",
      "0.16439435548041562\n",
      "0.08925015127956025\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "input_file = \"test_data/system_tests/lfqbench/DIANN/report.tsv.diann_fragion_isotopes_raw.aq_reformat.tsv.protein_intensities.tsv\"\n",
    "samplemap_file = \"test_data/system_tests/lfqbench/DIANN/samplemap.tsv\"\n",
    "\n",
    "biol_res = ResultsTableBiological(results_file=input_file, samplemap=samplemap_file, name=\"diann\")\n",
    "biol_res.cond2samples\n",
    "biol_res.results_df\n",
    "\n",
    "calced_cvs = CVInfoDataset(biol_res)\n",
    "ax = plt.subplot()\n",
    "CVDistributionPlotter([calced_cvs], ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create input dataframes with scalable number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import directlfq.lfq_manager as lfqmgr\n",
    "import directlfq.normalization as lfqnorm\n",
    "import directlfq.protein_intensity_estimation as lfq_protein_estimation\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "class SampleListScaler():\n",
    "    def __init__(self, sample_list, desired_number_of_samples):\n",
    "        self._sample_list = sample_list\n",
    "        self._desired_number_of_samples = desired_number_of_samples\n",
    "        \n",
    "        self.num_replicates_of_sample_list = None\n",
    "        self.num_remaining_samples = None\n",
    "\n",
    "        self.scaled_sample_list = []\n",
    "        self._define_scaled_sample_list()\n",
    "\n",
    "    def _define_scaled_sample_list(self):\n",
    "        self._define_number_of_replicates_of_samples()\n",
    "        self._define_number_of_remaining_samples()\n",
    "        self._append_replicate_sample_names_to_scaled_sample_list()\n",
    "        self._append_remaining_sample_names_to_scaled_sample_list()\n",
    "\n",
    "    def _define_number_of_replicates_of_samples(self):\n",
    "        num_samples_in_df = len(self._sample_list)\n",
    "        self.num_replicates_of_sample_list = math.floor(self._desired_number_of_samples/num_samples_in_df)\n",
    "    \n",
    "    def _define_number_of_remaining_samples(self):\n",
    "        num_samples_in_df = len(self._sample_list)\n",
    "        self.num_remaining_samples = self._desired_number_of_samples%num_samples_in_df\n",
    "\n",
    "    def _append_replicate_sample_names_to_scaled_sample_list(self):\n",
    "        for idx in range(self.num_replicates_of_sample_list):\n",
    "            self.scaled_sample_list += [f\"{x}_AND_{idx}\" for x in self._sample_list]\n",
    "\n",
    "    def _append_remaining_sample_names_to_scaled_sample_list(self):\n",
    "        self.scaled_sample_list +=[f\"{self._sample_list[x]}_AND_remainder\" for x in range(self.num_remaining_samples)]\n",
    "\n",
    "    @staticmethod\n",
    "    def get_original_sample_name(new_sample_name):\n",
    "        return new_sample_name.split(\"_AND_\")[0]\n",
    "\n",
    "\n",
    "class SampleIndexIQScaler(SampleListScaler):\n",
    "    def __init__(self, sample_index_list, desired_number_of_samples):\n",
    "        self._sample_list = sample_index_list\n",
    "        self._desired_number_of_samples = desired_number_of_samples\n",
    "        self.scaled_sample_list = []\n",
    "        \n",
    "    def _append_replicate_sample_names_to_scaled_sample_list(self):\n",
    "        for idx in range(self._num_replicates_of_sample_list):\n",
    "            offset_to_zero_idx = len(set(self._sample_list))*idx\n",
    "            self.scaled_sample_list += [ x + offset_to_zero_idx for x in self._sample_list]\n",
    "\n",
    "    def _append_remaining_sample_names_to_scaled_sample_list(self):\n",
    "        offset_to_zero_idx = self.scaled_sample_list[-1]+1\n",
    "        self.scaled_sample_list +=[x + offset_to_zero_idx for x in range(self._num_remaining_samples)]\n",
    "\n",
    "\n",
    "class ScaledDFCreatorDirectLFQFormat():\n",
    "    def __init__(self, template_df, desired_number_of_samples):\n",
    "        self._template_df = template_df\n",
    "        self._column_names = list(self._template_df.columns)\n",
    "        self._samplelist_scaler = SampleListScaler(self._column_names, desired_number_of_samples)         \n",
    "        self.scaled_df = None\n",
    "        self._create_scaled_dataframe()\n",
    "\n",
    "    def _create_scaled_dataframe(self):\n",
    "        template_dataframe_dict = self._template_df.to_dict(orient = 'list')\n",
    "        input_dataframe_dict = {x : template_dataframe_dict.get(self._samplelist_scaler.get_original_sample_name(x))  for x in self._samplelist_scaler.scaled_sample_list}\n",
    "        self.scaled_df = pd.DataFrame(input_dataframe_dict, index=self._template_df.index)\n",
    "\n",
    "\n",
    "class ScaledDFCreatorIQFormat():\n",
    "    def __init__(self, quant_df, sample_list_df, desired_number_of_samples):\n",
    "        self._quant_df = quant_df\n",
    "        self._sample_list = sample_list_df[\"sample_list\"]\n",
    "        self._desired_number_of_samples = desired_number_of_samples\n",
    "        self._create_scaled_quant_df()\n",
    "\n",
    "        self._samplelist_scaler = None\n",
    "        self._create_scaled_sample_list_df()\n",
    "\n",
    "    def _create_scaled_quant_df(self):\n",
    "        self._create_indexes_to_expand_quant_df()\n",
    "        self.scaled_quant_df = self._quant_df.set_index(\"sample_list\").loc[self._indexes_to_expand_quant_df]\n",
    "        self.scaled_quant_df[\"sample_list\"] = self._get_new_samples_column()\n",
    "        self.scaled_quant_df = self.scaled_quant_df.reset_index(drop= True)\n",
    "\n",
    "    def _create_scaled_sample_list_df(self):\n",
    "        self._samplelist_scaler = SampleListScaler(sample_list = self._sample_list, desired_number_of_samples= len(set(self.scaled_quant_df[\"sample_list\"])))\n",
    "        self.scaled_sample_list_df = pd.DataFrame({\"sample_list\" : self._samplelist_scaler.scaled_sample_list})\n",
    "\n",
    "    def _create_indexes_to_expand_quant_df(self):\n",
    "        num_scaled_samples = self._desired_number_of_samples\n",
    "        num_samples = len(self._sample_list)\n",
    "        indexes_of_scaled_sample_list = list(range(num_scaled_samples))\n",
    "        self._indexes_to_expand_quant_df = [x%num_samples for x in indexes_of_scaled_sample_list]\n",
    "\n",
    "    def _get_new_samples_column(self):\n",
    "        scaled_repeated_sample_list = self.scaled_quant_df.index\n",
    "        previous_sample = scaled_repeated_sample_list[0]\n",
    "        new_sample_list = [0]\n",
    "\n",
    "        sample_id = 0\n",
    "        for sample in scaled_repeated_sample_list[1:]:\n",
    "            if sample != previous_sample:\n",
    "                sample_id +=1\n",
    "                previous_sample = sample\n",
    "            new_sample_list.append(sample_id)\n",
    "            \n",
    "        return new_sample_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test input df creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "quant_df  = pd.DataFrame({'sample_list' : [0, 0, 1, 2, 2, 2, 2], 'asd' : ['a', 'b', 'c', 'd', 'e', 'f', 'g'], 'cfs' : [11, 23, 4, 5, 7, 4, 9]})\n",
    "samplelist_df = pd.DataFrame({'sample_list' : ['s1', 's2', 's3']})\n",
    "\n",
    "def test_that_scaled_numbers_of_samples_are_as_expected(quant_df, samplelist_df,desired_num_samples):    \n",
    "    scaled_df_creator = ScaledDFCreatorIQFormat(quant_df, samplelist_df, desired_num_samples)\n",
    "    assert len(set(scaled_df_creator.scaled_quant_df[\"sample_list\"])) == desired_num_samples\n",
    "    assert len(scaled_df_creator.scaled_sample_list_df.index) == desired_num_samples\n",
    "\n",
    "\n",
    "test_that_scaled_numbers_of_samples_are_as_expected(quant_df, samplelist_df, 1)\n",
    "test_that_scaled_numbers_of_samples_are_as_expected(quant_df, samplelist_df, 7)\n",
    "test_that_scaled_numbers_of_samples_are_as_expected(quant_df, samplelist_df, 13)\n",
    "\n",
    "\n",
    "def test_that_repetition_worked_out(quant_df, samplelist_df):\n",
    "    scaled_df_creator = ScaledDFCreatorIQFormat(quant_df, samplelist_df, 7)\n",
    "    assert np.alltrue(scaled_df_creator.scaled_quant_df[\"sample_list\"][10:14] == [5 for x in range(4)])\n",
    "\n",
    "test_that_repetition_worked_out(quant_df, samplelist_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performed_checks\n",
      "performed_checks\n",
      "performed_checks\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "class TemplateDFCreator():\n",
    "    def __init__(self):\n",
    "\n",
    "        self.template_df = None\n",
    "        self._template_df_location = \"test_data/unit_tests/protein_normalization/example_proteins.tsv\"\n",
    "        self._create_template_df()\n",
    "\n",
    "    def _create_template_df(self):\n",
    "        self.template_df = pd.read_csv(self._template_df_location, index_col= [\"protein\", \"ion\"], sep = \"\\t\")\n",
    "\n",
    "\n",
    "def test_that_shape_is_as_expected(num_samples):\n",
    "    template_df = TemplateDFCreator().template_df\n",
    "    size_adjusted_df = ScaledDFCreatorDirectLFQFormat(template_df=template_df, desired_number_of_samples= num_samples).scaled_df\n",
    "    assert len(size_adjusted_df.columns) == num_samples\n",
    "    assert len(size_adjusted_df.index) == len(template_df.index)\n",
    "    print(\"performed_checks\")\n",
    "\n",
    "\n",
    "test_that_shape_is_as_expected(1)\n",
    "test_that_shape_is_as_expected(100)\n",
    "test_that_shape_is_as_expected(10000)\n",
    "\n",
    "def test_that_values_are_as_expected(num_samples):\n",
    "    template_df = TemplateDFCreator().template_df\n",
    "    size_adjusted_df = ScaledDFCreatorDirectLFQFormat(template_df=template_df, desired_number_of_samples= num_samples).scaled_df\n",
    "    assert np.allclose(template_df.loc[:,\"BoxCar_02-01_2\"], size_adjusted_df.loc[:, \"BoxCar_02-01_2_AND_remainder\"])\n",
    "\n",
    "\n",
    "test_that_values_are_as_expected(5)\n",
    "test_that_values_are_as_expected(100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export        \n",
    "\n",
    "class TimedLFQRun():\n",
    "    def __init__(self, formatted_df, name):\n",
    "        self.name = name\n",
    "        self.runtime_info = RuntimeInfo()\n",
    "        self.num_samples = len(formatted_df.columns)\n",
    "        self._formatted_df = formatted_df\n",
    "        self._run_from_formatted_df()\n",
    "\n",
    "    def _run_from_formatted_df(self):\n",
    "        self.runtime_info._start_samplenorm = time.time()\n",
    "        input_df_normed = lfqnorm.NormalizationManagerSamples(self._formatted_df, num_samples_quadratic=100).complete_dataframe\n",
    "        self.runtime_info._end_samplenorm = time.time()\n",
    "        self.runtime_info._start_protein_norm = time.time()\n",
    "        lfq_protein_estimation.estimate_protein_intensities(input_df_normed,min_nonan=1, num_samples_quadratic=10)\n",
    "        self.runtime_info._end_protein_norm = time.time()\n",
    "        self.runtime_info.calculate_runtimes()\n",
    "\n",
    "class RuntimeInfo():\n",
    "    def __init__(self):\n",
    "        self._start_samplenorm= None\n",
    "        self._end_samplenorm = None\n",
    "        self._start_protein_norm = None\n",
    "        self._end_protein_norm = None\n",
    "\n",
    "        self.overall_runtime = None\n",
    "        self.runtime_samplenorm = None\n",
    "        self.runtime_protein_norm = None\n",
    "\n",
    "    def calculate_runtimes(self):\n",
    "        self.overall_runtime = (self._end_protein_norm - self._start_samplenorm)/60\n",
    "        self.runtime_samplenorm = (self._end_samplenorm - self._start_samplenorm)/60\n",
    "        self.runtime_protein_norm = (self._end_protein_norm - self._start_protein_norm)/60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import directlfq.utils as lfq_utils\n",
    "\n",
    "class LFQTimer():\n",
    "    def __init__(self, template_file, list_of_samplenumbers_to_check, name):\n",
    "        self._template_file = template_file\n",
    "        self._samplenumbers_to_check = list_of_samplenumbers_to_check\n",
    "        self._name = name\n",
    "        self._template_df = None\n",
    "        self._read_template_file()\n",
    "        self.timed_lfq_runs = []\n",
    "        self._iterate_through_sizes()\n",
    "    \n",
    "    def _read_template_file(self):\n",
    "        self._template_df = pd.read_csv(self._template_file, sep = \"\\t\")\n",
    "        self._template_df = lfq_utils.index_and_log_transform_input_df(self._template_df)\n",
    "\n",
    "    def _iterate_through_sizes(self):\n",
    "        for samplenumber in self._samplenumbers_to_check:\n",
    "            formatted_df = InputDFCreator(self._template_df, desired_number_of_samples=samplenumber).input_df\n",
    "            self.timed_lfq_runs.append(TimedLFQRun(formatted_df,self._name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          NaN           1.5          0.2     setosa\n",
       "4             5.0          NaN           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def check_taking_mean_of_pandas_columns():\n",
    "    df = sns.load_dataset('iris')\n",
    "    display(df)\n",
    "    df.iloc[3:6, 1] = np.nan\n",
    "    display(df)\n",
    "    df['mean_sepal_width_petal_length'] = df[[\"sepal_width\", \"petal_length\"]].median(axis = 1, skipna = True)\n",
    "    assert df.loc[3, 'mean_sepal_width_petal_length'] == df.loc[3, 'petal_length']\n",
    "\n",
    "\n",
    "check_taking_mean_of_pandas_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "0             5.1          3.5           1.4          0.2\n",
       "1             4.9          3.0           1.4          0.2\n",
       "2             4.7          3.2           1.3          0.2\n",
       "3             4.6          3.1           1.5          0.2\n",
       "4             5.0          3.6           1.4          0.2\n",
       "..            ...          ...           ...          ...\n",
       "145           6.7          3.0           5.2          2.3\n",
       "146           6.3          2.5           5.0          1.9\n",
       "147           6.5          3.0           5.2          2.0\n",
       "148           6.2          3.4           5.4          2.3\n",
       "149           5.9          3.0           5.1          1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      0.854686\n",
       "1      0.857663\n",
       "2      0.849999\n",
       "3      0.813720\n",
       "4      0.845642\n",
       "         ...   \n",
       "145    0.470128\n",
       "146    0.528880\n",
       "147    0.490238\n",
       "148    0.414200\n",
       "149    0.476999\n",
       "Length: 150, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "def check_cv_calculation_along_a_dataframe_axis():\n",
    "        \n",
    "    df_test = sns.load_dataset(\"iris\").drop(labels = \"species\", axis = 1)\n",
    "    cv_function = lambda x: np.std(x, ddof=1,) / np.mean(x)\n",
    "    cv_results = df_test.apply(cv_function, axis=1)\n",
    "    display(df_test)\n",
    "    display(cv_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
