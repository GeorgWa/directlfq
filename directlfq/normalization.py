# AUTOGENERATED! DO NOT EDIT! File to edit: 02_normalization.ipynb (unless otherwise specified).

__all__ = ['get_normfacts', 'set_samples_with_only_single_intensity_to_nan', 'apply_sampleshifts', 'get_bestmatch_pair',
           'create_distance_matrix', 'calc_distance', 'calc_nanvar', 'calc_nanmedian', 'update_distance_matrix',
           'get_fcdistrib', 'determine_anchor_and_shift_sample', 'shift_samples', 'get_total_shift', 'merge_distribs',
           'normalize_dataframe_between_samples', 'normalize_ion_profiles', 'drop_nas_if_possible',
           'calculate_fraction_with_no_NAs', 'NormalizationManager', 'NormalizationManagerSamples',
           'NormalizationManagerProtein', 'SampleShifterLinearToMedian', 'SampleShifterLinear']

# Cell
import numpy as np
import pandas as pd
import time

def get_normfacts(samples):##row is the sample column is the features

    "finds optimal scaling factors for samples measured in the same condition and corrects the samples by these scaling factors. Takes a 2d numpy array as input  "
    set_samples_with_only_single_intensity_to_nan(samples)
    num_samples = samples.shape[0]
    mergedsamples = np.copy(samples) #the virtual "merged" samples will be stored in this array
    sampleidx2shift = dict(zip(range(num_samples), np.zeros(num_samples))) #the scaling factors applied to the samples are stored here
    sampleidx2counts = dict(zip(range(num_samples), np.ones(num_samples)))#keeps track of how many distributions are merged
    sampleidx2anchoridx = {} #keeps track of the shifted samples
    exclusion_set = set() #already clustered samples are stored here
    distance_matrix = create_distance_matrix(samples)
    variance_matrix = create_distance_matrix(samples, metric = 'variance')
    #print(f"distance matrix start\n{distance_matrix}")

    for rep in range(num_samples-1):
        #anchor_idx, shift_idx, min_distance = get_bestmatch_pair(mergedsamples, exclusion_set, sampleidx2counts)
        anchor_idx, shift_idx, min_distance = get_bestmatch_pair(distance_matrix,variance_matrix, sampleidx2counts)

        # #determine the closest pair of samples (one "shift" sample to be shifted and one "anchor sample which stays the same") and the distance between this pair
        #update the sets

        if(anchor_idx == None):
            break
        sampleidx2anchoridx.update({shift_idx : anchor_idx})
        sampleidx2shift.update({shift_idx : min_distance })
        exclusion_set.add(shift_idx)

        anchor_sample = mergedsamples[anchor_idx]
        shift_sample = samples[shift_idx]
        shifted_sample = shift_sample + min_distance

        merged_sample = merge_distribs(anchor_sample, shifted_sample, sampleidx2counts[anchor_idx], sampleidx2counts[shift_idx])
        mergedsamples[anchor_idx] = merged_sample


        update_distance_matrix(variance_matrix, mergedsamples, anchor_idx, shift_idx, metric='variance')
        update_distance_matrix(distance_matrix, mergedsamples, anchor_idx, shift_idx)

        #print(f"distance matrix after\n{distance_matrix}")
        sampleidx2counts[anchor_idx]+=1

    sampleidx2totalshift = {}
    for i in exclusion_set:
        shift = get_total_shift(sampleidx2anchoridx, sampleidx2shift, i)
        sampleidx2totalshift[i] = shift
        #samples[i] = samples[i]+shift
    return sampleidx2totalshift
    #return samples

def set_samples_with_only_single_intensity_to_nan(samples):
    for idx in range(len(samples)):
        sample = samples[idx]
        if sum(~np.isnan(sample)) <2:
            sample[:] = np.nan


def apply_sampleshifts(samples, sampleidx2shift):
    for idx in sampleidx2shift.keys():
        samples[idx] = samples[idx] + sampleidx2shift.get(idx)
    return samples

# Cell
def get_bestmatch_pair(distance_matrix, variance_matrix, sample2counts):

    i,j = np.unravel_index(np.argmin(variance_matrix, axis=None), variance_matrix.shape)
    min_distance = distance_matrix[i,j]
    #print(f"idxs are {i}, {j} median is {distance_matrix[i][j]} variance is {variance_matrix[i][j]}")
    if(min_distance == np.inf):
        return None, None, None
    anchor_idx, shift_idx, min_distance = determine_anchor_and_shift_sample(sample2counts,i, j, min_distance) #direction flip of distance if necessary
    return anchor_idx, shift_idx, min_distance


# Cell
def create_distance_matrix(samples, metric = 'median'):
    num_samples = samples.shape[0]
    distance_matrix = np.full((num_samples, num_samples), np.inf)
    for i in range(num_samples):
        for j in range(i+1, num_samples):#do every comparison once
            distance_matrix[i,j] = calc_distance(metric, samples[i], samples[j]) #the median of the shifted distribution is taken as the distance measure

    return distance_matrix


# Cell
from numba import njit

def calc_distance(metric, samples_1, samples_2):
    res = None

    if metric == 'median':
        res = calc_nanmedian(get_fcdistrib(samples_1, samples_2))#the median of the shifted distribution is taken as the distance measure
    if(metric == 'variance'):
        fcdist = get_fcdistrib(samples_1, samples_2)
        #if sum(~np.isnan(fcdist))<3:
         #   return 1000.0
        res = calc_nanvar(fcdist)
    if metric == 'overlap':
        fcdist = get_fcdistrib(samples_1, samples_2)
        res = sum(~np.isnan(fcdist))
    if res == None:
        raise Exception(f"distance metric {metric} not implemented")
    if(np.isnan(res)):
        return np.inf
    else:
        return res

@njit
def calc_nanvar(fcdist):
    return np.nanvar(fcdist)

@njit
def calc_nanmedian(fcdist):
    return np.nanmedian(fcdist)


# Cell
def update_distance_matrix(distance_matrix, merged_samples, merged_sample_idx, shift_idx,metric ='median'):
    "determine the distances to the newly merged sample"
    for i in range(0, merged_sample_idx):#update rows of distance matrix
        if distance_matrix[i, merged_sample_idx]==np.inf:#do not compare already merged samples
            continue
        distance = calc_distance(metric,merged_samples[i], merged_samples[merged_sample_idx])
        distance_matrix[i, merged_sample_idx] = distance

    for j in range(merged_sample_idx+1, merged_samples.shape[0]):#update columns of distance matrix
        if distance_matrix[merged_sample_idx, j] == np.inf:
            continue
        distance = calc_distance(metric,merged_samples[merged_sample_idx], merged_samples[j])
        distance_matrix[merged_sample_idx, j] = distance

    distance_matrix[shift_idx] = np.inf #shifted samples are excluded by setting distance to infinity
    distance_matrix[:, shift_idx] = np.inf


# Cell
def get_fcdistrib(logvals_rep1, logvals_rep2):
    "generates difference distribution between two samples"
    dist = np.subtract(logvals_rep1, logvals_rep2)
    return dist

# Cell
def determine_anchor_and_shift_sample(sample2counts, i_min, j_min, min_distance):
    "given two samples, declare the sample with fewer merges as the shift"
    counts_i = sample2counts[i_min]
    counts_j = sample2counts[j_min]
    anchor_idx = i_min if counts_i>=counts_j else j_min
    shift_idx = j_min if anchor_idx == i_min else i_min
    flip = 1 if anchor_idx == i_min else -1
    return anchor_idx, shift_idx, flip*min_distance

# Cell
def shift_samples(samples, sampleidx2anchoridx, sample2shift):
    for sample_idx in range(samples.shape[0]):
        samples[sample_idx] = samples[sample_idx]+get_total_shift(sampleidx2anchoridx, sample2shift, sample_idx)

# Cell
def get_total_shift(sampleidx2anchoridx, sample2shift,sample_idx):

    total_shift = 0.0

    while(True):
        total_shift +=sample2shift[sample_idx]
        if sample_idx not in sampleidx2anchoridx: #every shifted sample has an anchor
            break
        sample_idx = sampleidx2anchoridx[sample_idx]

    return total_shift

# Cell
import time
import numpy as np

def merge_distribs(anchor_distrib, shifted_distrib,counts_anchor_distrib, counts_shifted_distrib):
    "Calculate the average peptide intensities to merge two peptide distributions"

    t_alt = time.time()
    res = np.zeros(len(anchor_distrib))

    nans_anchor = np.isnan(anchor_distrib)
    nans_shifted = np.isnan(shifted_distrib)
    nans_anchor_and_shifted = nans_anchor & nans_shifted
    nans_only_anchor = nans_anchor & ~nans_shifted
    nans_only_shifted = nans_shifted &~nans_anchor
    no_nans = ~nans_anchor & ~nans_shifted

    idx_anchor_and_shifted = np.where(nans_anchor_and_shifted)
    idx_only_anchor = np.where(nans_only_anchor)
    idx_only_shifted = np.where(nans_only_shifted)
    idx_no_nans = np.where(no_nans)

    res[idx_anchor_and_shifted] = np.nan
    res[idx_only_anchor] = shifted_distrib[idx_only_anchor]
    res[idx_only_shifted] = anchor_distrib[idx_only_shifted]
    res[idx_no_nans] = (anchor_distrib[idx_no_nans] *counts_anchor_distrib + shifted_distrib[idx_no_nans]*counts_shifted_distrib)/(counts_anchor_distrib+counts_shifted_distrib)
    return res

# Cell
import pandas as pd


def normalize_dataframe_between_samples(ion_dataframe):
    sample2shift = get_normfacts(drop_nas_if_possible(ion_dataframe).to_numpy())
    df_c_normed = pd.DataFrame(apply_sampleshifts(ion_dataframe.to_numpy(), sample2shift), index = ion_dataframe.index, columns = ion_dataframe.columns)
    return df_c_normed

def normalize_ion_profiles(protein_profile_df):
    protein_profile_numpy = protein_profile_df.to_numpy()
    sample2shift = get_normfacts(protein_profile_numpy)
    df_normed = pd.DataFrame(apply_sampleshifts(protein_profile_numpy, sample2shift), index = protein_profile_df.index, columns = protein_profile_df.columns)
    return df_normed


def drop_nas_if_possible(df):
    df_nonans = df.dropna(axis=0)
    fraction_nonans = calculate_fraction_with_no_NAs(df, df_nonans)
    if fraction_nonans<0.05:
        print('to few values for normalization without missing values. Including missing values')
        return df
    else:
        return df_nonans

def calculate_fraction_with_no_NAs(df, df_nonnans):
    return len(df_nonnans.index)/len(df.index)



# Cell

class NormalizationManager():
    def __init__(self, complete_dataframe, num_samples_quadratic = 100):
        self.complete_dataframe = complete_dataframe
        self._num_samples_quadratic = num_samples_quadratic
        self._rows_sorted_by_number_valid_values = None
        self._quadratic_subset_rows = None
        self._linear_subset_rows = None
        self._merged_reference_sample = None #pd.Series with mean intensity
        self.normalization_function = None

    def _run_normalization(self):
        if len(self.complete_dataframe.index) <= self._num_samples_quadratic:
            self._normalize_complete_input_quadratic()
        else:
            self._normalize_quadratic_and_linear()

    def _normalize_complete_input_quadratic(self):
        self.complete_dataframe =  self.normalization_function(self.complete_dataframe)

    def _normalize_quadratic_and_linear(self):
        self._determine_subset_rows()
        self._normalize_quadratic_selection()
        self._create_reference_sample()
        self._shift_remaining_dataframe_to_reference_sample()

    def _determine_subset_rows(self):
        self._determine_sorted_rows()
        self._quadratic_subset_rows = self._rows_sorted_by_number_valid_values[:self._num_samples_quadratic]
        self._linear_subset_rows = [x for x in self.complete_dataframe.index if x not in self._quadratic_subset_rows]

    def _determine_sorted_rows(self):
        rows = self.complete_dataframe.index
        self._rows_sorted_by_number_valid_values =  sorted(rows, key= lambda idx : self._get_num_nas_in_row(self.complete_dataframe.loc[idx,:]))

    def _normalize_quadratic_selection(self):
        quadratic_subset_dataframe = self.complete_dataframe.loc[self._quadratic_subset_rows]
        self.complete_dataframe.loc[self._quadratic_subset_rows,:] = self.normalization_function(quadratic_subset_dataframe)

    def _create_reference_sample(self):
        quadratic_subset_dataframe = self.complete_dataframe.loc[self._quadratic_subset_rows]
        self._merged_reference_sample = quadratic_subset_dataframe.median(axis=0)

    def _shift_remaining_dataframe_to_reference_sample(self):
        linear_subset_dataframe = self.complete_dataframe.loc[self._linear_subset_rows]
        linear_shifted_dataframe = SampleShifterLinear(linear_subset_dataframe, self._merged_reference_sample).ion_dataframe
        self.complete_dataframe.loc[ self._linear_subset_rows, :] = linear_shifted_dataframe

    @staticmethod
    def _get_num_nas_in_row(row):
        return sum(np.isnan(row.to_numpy()))

class NormalizationManagerSamples(NormalizationManager):
    def __init__(self, complete_dataframe, num_samples_quadratic):
        complete_dataframe = complete_dataframe.T #the samples to shift are in each row, therefore the df needs to be transposed
        super().__init__(complete_dataframe, num_samples_quadratic)
        self.normalization_function = normalize_dataframe_between_samples
        self._run_normalization()
        self.complete_dataframe = complete_dataframe.T

class NormalizationManagerProtein(NormalizationManager):
    def __init__(self, complete_dataframe, num_samples_quadratic):
        super().__init__(complete_dataframe, num_samples_quadratic)
        self.normalization_function = normalize_ion_profiles
        self._rows_sorted_by_number_valid_values = None
        self._run_normalization()



# Cell

class SampleShifterLinearToMedian():
    def __init__(self, ion_dataframe):
        self.ion_dataframe = ion_dataframe
        self._merged_reference_sample = ion_dataframe.median(axis=0)
        self._shift_to_median()

    def _shift_to_median(self):
        self.ion_dataframe = SampleShifterLinear(self.ion_dataframe, self._merged_reference_sample).ion_dataframe



# Cell
class SampleShifterLinear():
    def __init__(self, ion_dataframe, reference_column):
        self.ion_dataframe = ion_dataframe
        self._ion_dataframe_values = ion_dataframe.to_numpy()
        self._reference_column = reference_column.to_numpy()
        self._shift_columns_to_reference_sample()
        self._update_ion_dataframe()

    def _shift_columns_to_reference_sample(self):
        num_rows = self._ion_dataframe_values.shape[0]
        for row_idx in range(num_rows):
            self._shift_to_reference_sample(row_idx)

    def _shift_to_reference_sample(self, row_idx):
        distance_to_reference = calc_distance(metric='median', samples_1=self._reference_column, samples_2=self._ion_dataframe_values[row_idx,:]) #reference-sample = distance
        self._ion_dataframe_values[row_idx, :] += distance_to_reference

    def _update_ion_dataframe(self):
        self.ion_dataframe.loc[:,:] = self._ion_dataframe_values